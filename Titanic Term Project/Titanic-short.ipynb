{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# one-hot encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "#bayesian optimization\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "#garbage collection\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_df = pd.read_csv('./Data/train.csv')\n",
    "test_df = pd.read_csv('./Data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples are 891\n",
      "Test data is 418\n",
      "The columns are ['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch'\n",
      " 'Ticket' 'Fare' 'Cabin' 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "print(\"Training examples are\",len(train_df))\n",
    "print(\"Test data is\",len(test_df))\n",
    "print(\"The columns are\",train_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview the first 5 rows\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning\n",
    "\n",
    "combined_data = train_df.append(test_df)\n",
    "\n",
    "combined_data.Age.fillna(value=combined_data.Age.mean(), inplace=True)\n",
    "combined_data.Fare.fillna(value=combined_data.Fare.mean(), inplace=True)\n",
    "combined_data.Embarked.fillna(value=(combined_data.Embarked.value_counts().idxmax()), inplace=True)\n",
    "combined_data.Survived.fillna(value=-1, inplace=True) \n",
    "\n",
    "# drop columns that are not needed\n",
    "combined_data.drop('Name', axis=1, inplace=True)\n",
    "combined_data.drop('Cabin', axis=1, inplace=True)\n",
    "combined_data.drop('Ticket', axis=1, inplace=True)\n",
    "combined_data.drop('Embarked', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Write cleaned data out\n",
    "\n",
    "train = combined_data[combined_data['Survived']!=-1]\n",
    "# train.to_csv(\"./Data/train-clean.csv\")\n",
    "\n",
    "test = combined_data[combined_data['Survived']==-1]\n",
    "test.drop('Survived', axis=1, inplace=True)\n",
    "# test.to_csv(\"./Data/test-clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Fare', 'Parch', 'Sex_female', 'Sex_male', 'SibSp', 'Survived']\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding\n",
    "train_encoded = pd.get_dummies(train, columns = ['Sex'])\n",
    "test_encoded = pd.get_dummies(test, columns = ['Sex'])\n",
    "\n",
    "# Rearrange columns\n",
    "list_of_features = ['Age','Fare','Parch','Sex_female','Sex_male','SibSp']\n",
    "list_of_columns = list_of_features + ['Survived']\n",
    "train_encoded = train_encoded[list_of_columns]\n",
    "test_encoded = test_encoded[list_of_features]\n",
    "\n",
    "# Transform training and testing data into np arrays\n",
    "train_x = train_encoded[list_of_features].values\n",
    "test_x = test_encoded[list_of_features].values\n",
    "train_y = train_encoded['Survived'].values\n",
    "\n",
    "print(list_of_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collect some trash\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell defines functions to compute the performance of any given model.\n",
    "\"\"\"\n",
    "\n",
    "def compute_f1(model, X, y,k_folds):\n",
    "    \"\"\"\n",
    "    Given a model and the evaluation data, returns the F1 score.\n",
    "    \"\"\"\n",
    "    return np.mean(cross_val_score(model, X, y, cv=k_folds, scoring='f1_weighted'))\n",
    "\n",
    "def accuracy(model, X, y,k_folds):\n",
    "    \"\"\"\n",
    "    Given a model and the evaluation data, returns the accuracy\n",
    "    score evaluated using cross validation.\n",
    "    \"\"\"\n",
    "    return np.mean(cross_val_score(model, X, y, cv=k_folds, scoring='accuracy'))\n",
    "\n",
    "def print_score_model(model,train_x,train_y, k_folds):\n",
    "    print(\"F1 score is\",compute_f1(model,train_x,train_y,k_folds))\n",
    "    print(\"Accuracy is\",accuracy(model,train_x,train_y,k_folds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtree(max_depth=None):\n",
    "    # Decision tree classifier\n",
    "    clf = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    return clf\n",
    "\n",
    "def dtree_adaboost(n_estimators = 50):\n",
    "    # Single layer decision trees with AdaBoost\n",
    "    single_tree = dtree(max_depth=1)\n",
    "    clf = AdaBoostClassifier(single_tree, algorithm='SAMME', n_estimators= n_estimators)\n",
    "    return clf\n",
    "\n",
    "def random_forest():\n",
    "    #Random forest classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    return clf\n",
    "\n",
    "def SVM(kernel, degree=3, C=1.0, gamma='auto'):\n",
    "    # Support vector machines\n",
    "    clf = svm.SVC(kernel=kernel, degree=degree, C=C, gamma=gamma)\n",
    "    return clf\n",
    "\n",
    "def kNN(n_neighbor=3):\n",
    "    # k nearest neighbours\n",
    "    clf = KNeighborsClassifier(n_neighbor)\n",
    "    return clf\n",
    "\n",
    "def xgboost(max_depth=3, n_estimators=200, learning_rate=0.05):\n",
    "    #gradient boosting for decision trees\n",
    "    clf = xgb.XGBClassifier(max_depth = max_depth, \n",
    "                            n_estimators = n_estimators, \n",
    "                            learning_rate=learning_rate)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is 0.786988243645\n",
      "Accuracy is 0.790132221087\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model = LogisticRegression()\n",
    "print_score_model(logistic_regression_model,train_x,train_y,10)\n",
    "# logistic_regression_model.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1 kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is 0.719810544843\n",
      "Accuracy is 0.72410225854\n"
     ]
    }
   ],
   "source": [
    "knn_model = kNN(3)\n",
    "print_score_model(knn_model,train_x,train_y,10)\n",
    "# knn_model.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is 0.813744334154\n",
      "Accuracy is 0.812680456248\n"
     ]
    }
   ],
   "source": [
    "randomforest_model = random_forest()\n",
    "print_score_model(randomforest_model,train_x,train_y,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.3 Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is 0.789856384786\n",
      "Accuracy is 0.791356259221\n"
     ]
    }
   ],
   "source": [
    "adaboosted_model = dtree_adaboost(100)\n",
    "print_score_model(adaboosted_model,train_x,train_y,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is 0.825289484397\n",
      "Accuracy is 0.827224775848\n"
     ]
    }
   ],
   "source": [
    "xgboost_model = xgboost(max_depth=3, \n",
    "                        n_estimators=300, \n",
    "                        learning_rate=0.05).fit(train_x, train_y)\n",
    "print_score_model(xgboost_model, train_x, train_y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tuned = xgb.XGBClassifier(reg_alpha = 4.1764, \n",
    "                              colsample_bytree = 1, \n",
    "                              gamma=0,\n",
    "                              max_depth = 9, \n",
    "                              min_child_weight=19.7516,\n",
    "                              subsample =1.00,\n",
    "                              n_estimators=200, \n",
    "                              learning_rate=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is 0.782991024969\n",
      "Accuracy is 0.785612019067\n"
     ]
    }
   ],
   "source": [
    "print_score_model(xgb_tuned, train_x, train_y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collect some trash\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM with parameters obtained from bayesian optimization in MATLAB\n",
    "linear_svm_model = svm.SVC(C=60.397, kernel='linear')\n",
    "print_score_model(linear_svm_model, train_x, train_y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svm_model = svm.SVC(C=60.397, kernel='poly', degree=4)\n",
    "print_score_model(linear_svm_model, train_x, train_y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization on XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[96]\ttrain-mae:0.396608+0.00498\ttest-mae:0.398111+0.00874543\n",
      "\n",
      "    1 | 00m01s | \u001b[35m  -0.39811\u001b[0m | \u001b[32m   7.8772\u001b[0m | \u001b[32m            0.9587\u001b[0m | \u001b[32m   5.3540\u001b[0m | \u001b[32m     7.4250\u001b[0m | \u001b[32m            2.9227\u001b[0m | \u001b[32m     0.5324\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[90]\ttrain-mae:0.362848+0.00436844\ttest-mae:0.368699+0.00774363\n",
      "\n",
      "    2 | 00m00s | \u001b[35m  -0.36870\u001b[0m | \u001b[32m   0.9008\u001b[0m | \u001b[32m            0.8102\u001b[0m | \u001b[32m   5.1850\u001b[0m | \u001b[32m     2.9072\u001b[0m | \u001b[32m            1.5099\u001b[0m | \u001b[32m     0.9560\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[101]\ttrain-mae:0.394442+0.00624551\ttest-mae:0.396137+0.00556214\n",
      "\n",
      "    3 | 00m00s |   -0.39614 |    3.1721 |             0.4264 |    9.8656 |      4.3105 |             8.6289 |      0.8892 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[76]\ttrain-mae:0.383229+0.00360722\ttest-mae:0.385652+0.00766871\n",
      "\n",
      "    4 | 00m01s |   -0.38565 |    1.5187 |             0.8733 |    7.7704 |     14.3913 |             1.4798 |      0.6867 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[177]\ttrain-mae:0.353098+0.00385685\ttest-mae:0.359635+0.0079211\n",
      "\n",
      "    5 | 00m02s | \u001b[35m  -0.35964\u001b[0m | \u001b[32m   0.1834\u001b[0m | \u001b[32m            0.9950\u001b[0m | \u001b[32m   5.0961\u001b[0m | \u001b[32m    11.4053\u001b[0m | \u001b[32m           14.4891\u001b[0m | \u001b[32m     0.7714\u001b[0m | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[45]\ttrain-mae:0.472845+0.00268504\ttest-mae:0.473178+0.00391875\n",
      "\n",
      "    6 | 00m08s |   -0.47318 |    0.1646 |             0.2050 |    0.0009 |      0.5252 |            17.2739 |      0.9280 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[98]\ttrain-mae:0.407818+0.00677308\ttest-mae:0.408694+0.00444275\n",
      "\n",
      "    7 | 00m13s |   -0.40869 |   10.0000 |             1.0000 |   10.0000 |     15.0000 |            20.0000 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[73]\ttrain-mae:0.39586+0.00755878\ttest-mae:0.396799+0.00809263\n",
      "\n",
      "    8 | 00m15s |   -0.39680 |    0.0000 |             0.1000 |   10.0000 |     15.0000 |            20.0000 |      0.5000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[40]\ttrain-mae:0.14472+0.00481549\ttest-mae:0.261985+0.019178\n",
      "\n",
      "    9 | 00m20s | \u001b[35m  -0.26198\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m            0.1000\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m    15.0000\u001b[0m | \u001b[32m            6.5630\u001b[0m | \u001b[32m     1.0000\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[75]\ttrain-mae:0.303804+0.00241221\ttest-mae:0.314529+0.0108242\n",
      "\n",
      "   10 | 00m15s |   -0.31453 |   10.0000 |             0.1000 |    0.0000 |     15.0000 |            20.0000 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[61]\ttrain-mae:0.303035+0.00289766\ttest-mae:0.313301+0.0117069\n",
      "\n",
      "   11 | 00m18s |   -0.31330 |   10.0000 |             0.1000 |    0.0000 |     15.0000 |             8.0337 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[59]\ttrain-mae:0.0320816+0.00229663\ttest-mae:0.241199+0.0179893\n",
      "\n",
      "   12 | 00m19s | \u001b[35m  -0.24120\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m            1.0000\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m    15.0000\u001b[0m | \u001b[32m            1.0000\u001b[0m | \u001b[32m     1.0000\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[44]\ttrain-mae:0.0897266+0.00292856\ttest-mae:0.25327+0.0145308\n",
      "\n",
      "   13 | 00m17s |   -0.25327 |    0.0000 |             0.1000 |    0.0000 |     15.0000 |             1.0000 |      0.5000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[44]\ttrain-mae:0.156165+0.00411422\ttest-mae:0.260738+0.0141231\n",
      "\n",
      "   14 | 00m18s |   -0.26074 |    0.0000 |             1.0000 |    0.0000 |     15.0000 |             4.2069 |      0.5000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[76]\ttrain-mae:0.218374+0.00530621\ttest-mae:0.273714+0.0125923\n",
      "\n",
      "   15 | 00m15s |   -0.27371 |    1.1915 |             1.0000 |    0.0000 |     15.0000 |            20.0000 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[90]\ttrain-mae:0.195263+0.00498826\ttest-mae:0.263986+0.0132413\n",
      "\n",
      "   16 | 00m15s |   -0.26399 |    1.9628 |             0.9451 |    0.0000 |     15.0000 |             1.0000 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[50]\ttrain-mae:0.0822014+0.00260811\ttest-mae:0.247791+0.0156879\n",
      "\n",
      "   17 | 00m12s |   -0.24779 |    0.0058 |             0.4969 |    0.0526 |     12.4031 |             1.1143 |      0.8893 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[113]\ttrain-mae:0.139494+0.00341589\ttest-mae:0.256098+0.0164194\n",
      "\n",
      "   18 | 00m15s |   -0.25610 |    0.0111 |             0.9448 |    0.2774 |     14.7091 |             2.9415 |      0.8568 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[67]\ttrain-mae:0.142147+0.00347942\ttest-mae:0.255553+0.015502\n",
      "\n",
      "   19 | 00m18s |   -0.25555 |    0.2183 |             0.9084 |    0.1685 |     14.6104 |             1.3185 |      0.7915 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00019197]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[151]\ttrain-mae:0.473295+0.00274958\ttest-mae:0.473646+0.00377031\n",
      "\n",
      "   20 | 00m14s |   -0.47365 |    9.5244 |             0.8257 |    0.1530 |      0.5590 |             1.6991 |      0.6825 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ -3.94664560e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[246]\ttrain-mae:0.2959+0.00555601\ttest-mae:0.308512+0.00729588\n",
      "\n",
      "   21 | 00m18s |   -0.30851 |    9.9885 |             0.2724 |    0.1129 |     14.4539 |             1.0537 |      0.7565 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ -2.06054410e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 58, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[102]\ttrain-mae:0.129887+0.00514447\ttest-mae:0.252965+0.0149328\n",
      "\n",
      "   22 | 00m19s |   -0.25296 |    0.0914 |             0.1420 |    0.0682 |      6.5575 |             1.9435 |      0.8628 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[68]\ttrain-mae:0.177992+0.00363329\ttest-mae:0.261678+0.0149299\n",
      "\n",
      "   23 | 00m19s |   -0.26168 |    0.0000 |             0.1000 |    0.0000 |      6.0112 |             5.2923 |      1.0000 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00011598]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[78]\ttrain-mae:0.140637+0.00458577\ttest-mae:0.254911+0.01333\n",
      "\n",
      "   24 | 00m24s |   -0.25491 |    0.0000 |             0.1000 |    0.0000 |      6.0311 |             1.0000 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[68]\ttrain-mae:0.090042+0.00662761\ttest-mae:0.25577+0.0160027\n",
      "\n",
      "   25 | 00m22s |   -0.25577 |    0.0000 |             0.1000 |    0.0000 |     10.5178 |             2.3652 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[106]\ttrain-mae:0.475908+0.00250691\ttest-mae:0.476234+0.00335549\n",
      "\n",
      "   26 | 00m14s |   -0.47623 |   10.0000 |             1.0000 |   10.0000 |      0.0000 |            20.0000 |      1.0000 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[177]\ttrain-mae:0.42368+0.00397677\ttest-mae:0.424352+0.00725774\n",
      "\n",
      "   27 | 00m14s |   -0.42435 |   10.0000 |             0.5700 |   10.0000 |     15.0000 |             1.0000 |      0.5348 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[46]\ttrain-mae:0.472767+0.00262974\ttest-mae:0.473086+0.00398078\n",
      "\n",
      "   28 | 00m12s |   -0.47309 |    0.1077 |             0.7877 |    0.1289 |      0.2606 |             5.1939 |      0.9119 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[173]\ttrain-mae:0.300895+0.0065335\ttest-mae:0.311619+0.00597913\n",
      "\n",
      "   29 | 00m12s |   -0.31162 |    9.7291 |             0.3032 |    0.1049 |      3.7743 |            19.8837 |      0.9074 | \n",
      "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
      "\n",
      "Will train until test-mae hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[82]\ttrain-mae:0.26618+0.00601836\ttest-mae:0.290478+0.00786851\n",
      "\n",
      "   30 | 00m12s |   -0.29048 |    4.1764 |             1.0000 |    0.0000 |      9.0520 |            19.7516 |      1.0000 | \n"
     ]
    }
   ],
   "source": [
    "def xgb_evaluate(min_child_weight,\n",
    "                 colsample_bytree,\n",
    "                 max_depth,\n",
    "                 subsample,\n",
    "                 gamma,\n",
    "                 alpha):\n",
    "\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['cosample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    params['alpha'] = max(alpha, 0)\n",
    "\n",
    "\n",
    "    cv_result = xgb.cv(params, xgtrain, num_boost_round=num_rounds, nfold=5,\n",
    "             seed=random_state,\n",
    "             callbacks=[xgb.callback.early_stop(10)])\n",
    "\n",
    "    return -cv_result['test-mae-mean'].values[-1]\n",
    "\n",
    "num_rounds = 3000\n",
    "random_state = 2016\n",
    "num_iter = 25\n",
    "init_points = 5\n",
    "params = {\n",
    "        'eta': 0.1,\n",
    "        'silent': 1,\n",
    "        'eval_metric': 'mae',\n",
    "        'verbose_eval': True,\n",
    "        'seed': random_state}\n",
    "    \n",
    "xgtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "\n",
    "xgbBO = BayesianOptimization(xgb_evaluate, {'min_child_weight': (1, 20),\n",
    "                                                'colsample_bytree': (0.1, 1),\n",
    "                                                'max_depth': (0, 15),\n",
    "                                                'subsample': (0.5, 1),\n",
    "                                                'gamma': (0, 10),\n",
    "                                                'alpha': (0, 10),\n",
    "                                                })\n",
    "xgbBO.maximize(init_points=init_points, n_iter=num_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission for Kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kNN\n",
    "\n",
    "predictions = knn_model.predict(test_x)\n",
    "submission = pd.DataFrame({ 'PassengerId': test_df['PassengerId'],\n",
    "                            'Survived': predictions })\n",
    "submission.to_csv(\"knn.csv\", \n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "\n",
    "predictions =logistic_regression_model.predict(test_x)\n",
    "submission = pd.DataFrame({ 'PassengerId': test_df['PassengerId'],\n",
    "                            'Survived': predictions })\n",
    "submission.to_csv(\"logistic.csv\", \n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaboost\n",
    "\n",
    "predictions = adaboosted_model.predict(test_x)\n",
    "submission = pd.DataFrame({ 'PassengerId': test_df['PassengerId'],\n",
    "                            'Survived': predictions })\n",
    "submission.to_csv(\"ada.csv\", \n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "predictions = xgb_tuned.predict(test_x)\n",
    "submission = pd.DataFrame({ 'PassengerId': test_df['PassengerId'],\n",
    "                            'Survived': predictions })\n",
    "submission.to_csv(\"non_one_hot_encoded_embarkedremoved_optimized_submission.csv\", \n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "predictions = randomforest_model.predict(test_x)\n",
    "submission = pd.DataFrame({ 'PassengerId': test_df['PassengerId'],\n",
    "                            'Survived': predictions })\n",
    "submission.to_csv(\"random_forest.csv\", \n",
    "                  index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
